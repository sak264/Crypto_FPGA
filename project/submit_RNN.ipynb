{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that here testing is done on .wav files. For testing on spectrogram , the readDir function can be changed accordingly. However here too, the MFCC features are calculated from decibel power spectrum only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import LSTM\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import log, dot, e\n",
    "import librosa\n",
    "from numpy.random import rand\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(X, t, testFraction=0.2, randomize = False):\n",
    "    \"\"\"\n",
    "    Split the data randomly into training and test sets\n",
    "    Use numpy functions only\n",
    "    Inputs:\n",
    "        X: (np array of len Nclips) input feature vectors\n",
    "        t: (np array of len Nclips) targets; one hot vectors\n",
    "        testFraction: (float) Nclips_test = testFraction * Nclips\n",
    "    Outputs:\n",
    "        X_train: training set\n",
    "        X_test: test set\n",
    "        t_train: training labels\n",
    "        t_test: test labels\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 5 MARKS\n",
    "\n",
    "    \n",
    "    test_samples = (int) (len(X)*testFraction )\n",
    "    \n",
    "    temp=np.arange(len(X))\n",
    "    np.random.shuffle(temp)\n",
    "    \n",
    "    \n",
    "    temp1 = temp[0: test_samples]\n",
    "    temp2 = temp[test_samples: len(X)]\n",
    "    \n",
    "   \n",
    "    \n",
    "    X_test = np.reshape(X[temp1[0]],(-1,1))\n",
    "    X_test = np.transpose(X_test)\n",
    "    \n",
    "    t_test = np.reshape(t[temp1[0]],(-1,1))\n",
    "    t_test = np.transpose(t_test)\n",
    "    for x in range(1,len(temp1)):\n",
    "        i=temp1[x]\n",
    "        a=np.reshape(X[i],(-1,1))\n",
    "        a=np.transpose(a)\n",
    "        b=np.reshape(t[i],(-1,1))\n",
    "        b=np.transpose(b)\n",
    "        X_test = np.concatenate((X_test,a))\n",
    "        t_test = np.concatenate((t_test,b))\n",
    "        \n",
    "    X_train = np.reshape(X[temp2[0]],(-1,1))\n",
    "    X_train = np.transpose(X_train)\n",
    "    \n",
    "    t_train = np.reshape(t[temp2[0]],(-1,1))\n",
    "    t_train = np.transpose(t_train)\n",
    "    for x in range(1,len(temp2)):\n",
    "        i=temp2[x]\n",
    "        a=np.reshape(X[i],(-1,1))\n",
    "        a=np.transpose(a)\n",
    "        b=np.reshape(t[i],(-1,1))\n",
    "        b=np.transpose(b)\n",
    "        X_train = np.concatenate((X_train,a))\n",
    "        t_train = np.concatenate((t_train,b))\n",
    "        \n",
    "    return X_train, t_train, X_test, t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_framewise(model,x_test):\n",
    "        '''\n",
    "        Framewise classification (speech or music)\n",
    "\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        lis=[]   \n",
    "\n",
    "        \n",
    "        for i in range(0,len(x_test)):\n",
    "            k=0\n",
    "            \n",
    "            temp =np.ones((1,2))\n",
    "            t2=len(x_test[i][0])\n",
    "            x=x_test[i][0]\n",
    "            print(x_test[i][0].shape)\n",
    "            t1= np.ones( (313-len(x_test[i][0]), 60  ))\n",
    "            x=np.concatenate((x,t1))\n",
    "            #print(x_test[i].shape)\n",
    "            x= x[np.newaxis,...]\n",
    "            feat_4 = model.model.predict(x)\n",
    "            \n",
    "            p=np.ones((313,2))\n",
    "                \n",
    "            for j in range(0,len(feat_4[0])):   \n",
    "                \n",
    "                if(feat_4[0][j][0] > 0.5):\n",
    "                    temp = np.concatenate( (temp, np.transpose(np.reshape([1,0] , (-1,1) ) ) ) ) \n",
    "                else:\n",
    "                    temp = np.concatenate((temp, np.transpose(np.reshape([0,1] , (-1,1) ) ) ) ) \n",
    "                    \n",
    "            #print(temp.shape)\n",
    "                    \n",
    "            temp = temp[1:t2+1]\n",
    "            \n",
    "                \n",
    "            \n",
    "            lis.append(temp)\n",
    "\n",
    "        ### WRITE YOUR CODE HERE - 5 MARKS\n",
    "\n",
    "        \n",
    "        \n",
    "        return lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_aggregate(y_pred_framewise):\n",
    "        '''\n",
    "        Aggregate frames to give a single class label (music or speech) to the entire audio file\n",
    "\n",
    "            \n",
    "        '''\n",
    "       \n",
    "\n",
    "        \n",
    "        y_hat= np.ones((1,2))\n",
    "        for i in range (0,len(y_pred_framewise)):\n",
    "            \n",
    "            zero=0\n",
    "            one=0\n",
    "            t=y_pred_framewise[i]\n",
    "            for j in range(0, len(t)):\n",
    "                \n",
    "                if(t[j][0] == 1):\n",
    "                    one+=1\n",
    "                else:\n",
    "                    zero+=1\n",
    "            if(one>zero):\n",
    "                y_hat= np.concatenate((y_hat, np.transpose(np.reshape([1,0] , (-1,1) ) ) )) \n",
    "                \n",
    "            else:\n",
    "                y_hat= np.concatenate((y_hat, np.transpose(np.reshape([0,1] , (-1,1) ) ) ))  \n",
    "\n",
    "        ### WRITE YOUR CODE HERE - 5 MARKS\n",
    "\n",
    "        y_hat=y_hat[1:]\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "def readDir(dirname, Fs = 16000):\n",
    "    \n",
    "    '''\n",
    "   This function divides input clip into parts of 10 seconds and outputs concatenated samples from all 10 seconds audio clips\n",
    "    '''  \n",
    "\n",
    "\n",
    "    no_samp_in_10_sec = 10* Fs\n",
    "    files = glob(dirname + '/*.wav')\n",
    "    x= np.ones((1,no_samp_in_10_sec))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for f in files:\n",
    "    \n",
    "        \n",
    "        samples = load_audio(f,Fs)\n",
    "       \n",
    "        if(len(samples) > no_samp_in_10_sec):\n",
    "            i=0\n",
    "            while(i + no_samp_in_10_sec <= len(samples) ):\n",
    "                temp= samples[i : i +  no_samp_in_10_sec].reshape(-1,1)\n",
    "                temp=np.transpose(temp)\n",
    "                x= np.concatenate((x,temp))\n",
    "                i=i+no_samp_in_10_sec\n",
    "        \n",
    "        \n",
    "        else:\n",
    "            temp=np.append(samples , np.zeros(no_samp_in_10_sec - len(samples) ) )\n",
    "            temp=np.reshape(temp,(-1,1))\n",
    "            temp = np.transpose(temp)\n",
    "            x=np.concatenate((x,temp))\n",
    "    \n",
    "    #print(k)\n",
    "    \n",
    "    return x[1:]\n",
    "\n",
    "\n",
    "    return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(filename, Fs = 16000):\n",
    "    '''\n",
    "    Inputs: \n",
    "        filename: (str) filename\n",
    "        Fs: (int) sampling rate\n",
    "    Output: \n",
    "        x: 1D np array \n",
    "    '''\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    x,sr=librosa.load(filename,sr=Fs)\n",
    "    x=np.array(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(X,y,test_size, validation_size):\n",
    "\n",
    "    \n",
    "    X_train,  y_train, X_test, y_test = splitData(X, y, test_size)\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    #X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validation_size)\n",
    "    X_train, y_train, X_validation, y_validation = splitData(X_train,y_train,0.1)\n",
    "    return X_train, X_validation, X_test, y_train, y_validation, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio2mfcc(x, n_mfcc = 20, Fs = 16000):\n",
    "    \n",
    "    '''\n",
    "    Compute Mel-frequency cepstral coefficients (MFCCs)\n",
    "    This function finds mfcc features and thier 1st and 2nd order differences, from the log power spectrum of the given audio clip\n",
    "    '''\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 3 MARKS\n",
    "    \n",
    "   \n",
    "    lis=[]\n",
    "    if(len(x.shape) <=1):\n",
    "        x= np.reshape(x, (1,len(x))) \n",
    "    \n",
    "    for i in range(0, len(x)):\n",
    "        \n",
    "        \n",
    "        n_fft = 1024\n",
    "        hop_length = 512\n",
    "        win_length = 1024\n",
    "        X = np.abs(librosa.stft(x[i], n_fft = n_fft, hop_length = hop_length, win_length = win_length, window='hann'))\n",
    "        X = librosa.power_to_db(X,ref=np.max)\n",
    "        \n",
    "        temp=pow(10,X/10)\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(y='none',S=temp, sr=16000, n_fft=n_fft, hop_length=hop_length, n_mels=20,win_length = win_length, window='hann')\n",
    "        log_mel_spectrogram = librosa.power_to_db(mel_spectrogram)\n",
    "        \n",
    "        \n",
    "        mfccs = librosa.feature.mfcc(y='none',S=log_mel_spectrogram, n_mfcc=20, sr=16000,hop_length = hop_length, win_length = win_length ,n_fft=n_fft,window='hann')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        delta_mfccs = librosa.feature.delta(mfccs)\n",
    "        delta2_mfccs = librosa.feature.delta(mfccs, order=2)\n",
    "        mfccs=np.concatenate((mfccs,delta_mfccs))\n",
    "        mfccs=np.concatenate((mfccs,delta2_mfccs))\n",
    "        mfccs=np.array(mfccs)\n",
    "        mfccs=np.transpose(mfccs)\n",
    "        lis.append(mfccs)\n",
    "    ### WRITE YOUR CODE HERE - 3 MARKS\n",
    "    \n",
    "    X=np.array(lis)\n",
    "\n",
    "     \n",
    "\n",
    "    return X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier: \n",
    "    '''\n",
    "    Create a linear classifier to classify each frame\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.W=np.random.rand(20,)\n",
    "    \n",
    "    def sigmoid(self, z): return 1 / (1 + e**(-z))\n",
    "    \n",
    "\n",
    "   \n",
    "    \n",
    "    def rnn( self,X_train, y_train, input_shape):\n",
    "        \n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(keras.layers.LSTM(64, input_shape=input_shape, return_sequences=True))\n",
    "        model.add(keras.layers.LSTM(64,  return_sequences=True))\n",
    "\n",
    "\n",
    "        model.add(TimeDistributed(\n",
    "        Dense(64, activation='relu')\n",
    "        ))\n",
    "        model.add(Dropout(.3))\n",
    "\n",
    "        model.add(TimeDistributed(\n",
    "        Dense(32, activation='relu')\n",
    "        ))\n",
    "        model.add(Dropout(.3))\n",
    "\n",
    "\n",
    "       \n",
    "        model.add(TimeDistributed(\n",
    "        Dense(2, activation='softmax')\n",
    "        ))\n",
    "\n",
    "        model.compile(optimizer='adam', loss=tf.losses.CategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "        model.fit(X_train, y_train, batch_size=32, epochs=100)\n",
    "\n",
    "    \n",
    "        \n",
    "        self.model=model\n",
    "    \n",
    "    def save_model(self, save_path):\n",
    "        '''\n",
    "        Save the trained model on local disk\n",
    "        Input:\n",
    "            save_path: location at which model is to be saved\n",
    "        Output:\n",
    "            None\n",
    "            \n",
    "        '''\n",
    "        ## Assuming save_path contains the file name too. If save_path contains only directory\n",
    "        ## name , uncomment the below line to save file as data.npy\n",
    "        \n",
    "        #save_path = save_path +'/data'\n",
    "        \n",
    "        data=self.W\n",
    "        np.save(save_path, data)\n",
    "        \n",
    "        ### WRITE YOUR CODE HERE - 0 MARKS\n",
    "            \n",
    "        return\n",
    "    \n",
    "    def load_model(self, load_path):\n",
    "        '''\n",
    "        Save the trained model on local disk\n",
    "        Input:\n",
    "            load_path: location from which model is to be loaded\n",
    "        Output:\n",
    "            None\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        ### WRITE YOUR CODE HERE - 0 MARKS\n",
    "        \n",
    "        ## Assuming load_path also contains the name of file which has to be loaded. If load_path only contains the\n",
    "        ## directory name, uncomment the below line and replace data.npy with file name.\n",
    "        \n",
    "        #load_path = load_path +'/data.npy'\n",
    "        \n",
    "        self.W = np.load(load_path)\n",
    "            \n",
    "        return\n",
    "\n",
    "\n",
    "    \n",
    "    def predict_framewise(self,x_test):\n",
    "        '''\n",
    "        Framewise classification (speech or music)\n",
    "        Input:\n",
    "            x_test: test set\n",
    "        Output:\n",
    "            y_pred_framewise = framewise prediction\n",
    "        '''\n",
    "        \n",
    "        lis = []\n",
    "        \n",
    "        if(len(x_test.shape) ==2 ):\n",
    "            x_test = np.reshape(x_test,(1,len(x_test) , len(x_test[0]) ))\n",
    "            \n",
    "\n",
    "        \n",
    "        for i in range(0,len(x_test)):\n",
    "            k=0\n",
    "            t=np.transpose(x_test[i])\n",
    "            temp =np.ones((1,2))\n",
    "            \n",
    "\n",
    "            feat_4 = self.model.predict(t)\n",
    "                \n",
    "                \n",
    "            for j in range(0,len(feat_4)):   \n",
    "                \n",
    "                if(feat_4[j][0] > 0.5):\n",
    "                    temp = np.concatenate( (temp, np.transpose(np.reshape([1,0] , (-1,1) ) ) ) ) \n",
    "                else:\n",
    "                    temp = np.concatenate((temp, np.transpose(np.reshape([0,1] , (-1,1) ) ) ) ) \n",
    "                    \n",
    "            #print(temp.shape)\n",
    "                    \n",
    "            temp = temp[1:]\n",
    "            temp=np.transpose(temp)\n",
    "                \n",
    "            \n",
    "            lis.append(temp)\n",
    "\n",
    "        ### WRITE YOUR CODE HERE - 5 MARKS\n",
    "\n",
    "        y_pred_framewise= np.array(lis)\n",
    "        \n",
    "        return y_pred_framewise \n",
    "    \n",
    "    def predict_aggregate(self,y_pred_framewise):\n",
    "        '''\n",
    "        Aggregate frames to give a single class label (music or speech) to the entire audio file\n",
    "        Input:\n",
    "            y_pred_framewise = framewise prediction\n",
    "        Output:\n",
    "            y_hat = frame aggregate (one-hot vectors)\n",
    "            \n",
    "        '''\n",
    "        if(len(y_pred_framewise.shape) ==2 ):\n",
    "            y_pred_framewise = np.reshape(y_pred_framewise, (1,2,len(y_pred_framewise[0])))        \n",
    "\n",
    "        \n",
    "        y_hat= np.ones((1,2))\n",
    "        for i in range (0,len(y_pred_framewise)):\n",
    "            \n",
    "            zero=0\n",
    "            one=0\n",
    "            t=np.transpose(y_pred_framewise[i])\n",
    "            for j in range(0, len(t)):\n",
    "                \n",
    "                if(t[j][0] == 1):\n",
    "                    one+=1\n",
    "                else:\n",
    "                    zero+=1\n",
    "            if(one>zero):\n",
    "                y_hat= np.concatenate((y_hat, np.transpose(np.reshape([1,0] , (-1,1) ) ) )) \n",
    "                \n",
    "            else:\n",
    "                y_hat= np.concatenate((y_hat, np.transpose(np.reshape([0,1] , (-1,1) ) ) ))  \n",
    "\n",
    "        ### WRITE YOUR CODE HERE - 5 MARKS\n",
    "\n",
    "        y_hat=y_hat[1:]\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCM(y, y_hat):\n",
    "    '''\n",
    "    Compute confusion matrix to evaluate your model\n",
    "    Inputs:\n",
    "        y = labels \n",
    "        y_hat = predicted output\n",
    "    Output:\n",
    "        confusion matrix: confusion matrix\n",
    "    '''\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 5 MARKS\n",
    "\n",
    "\n",
    "    metrics = np.array([[0,0], [0,0]])\n",
    "\n",
    "    \n",
    "    for i in range(0,len(y)):\n",
    "        if(y[i][0] == 1 and y_hat[i][0] == 1):\n",
    "            metrics[0][0]+=1\n",
    "        elif(y[i][0] == 1 and y_hat[i][0] == 0):\n",
    "            metrics[0][1] +=1\n",
    "        elif(y[i][0] == 0 and y_hat[i][0] == 1):\n",
    "            metrics[1][0] +=1\n",
    "        else:\n",
    "            metrics[1][1]+=1\n",
    "\n",
    "    confusion_matrix = metrics\n",
    "    return confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 4s 221ms/step - loss: 0.7405 - accuracy: 0.5066\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 2s 220ms/step - loss: 0.7027 - accuracy: 0.5472\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 2s 218ms/step - loss: 0.6940 - accuracy: 0.5489\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 2s 216ms/step - loss: 0.6928 - accuracy: 0.5490\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 1s 214ms/step - loss: 0.6920 - accuracy: 0.5497\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 2s 222ms/step - loss: 0.6918 - accuracy: 0.5501\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 1s 212ms/step - loss: 0.6910 - accuracy: 0.5530\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 2s 220ms/step - loss: 0.6894 - accuracy: 0.5592\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 2s 224ms/step - loss: 0.6869 - accuracy: 0.5700\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 2s 220ms/step - loss: 0.6826 - accuracy: 0.5847\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 1s 209ms/step - loss: 0.6784 - accuracy: 0.5927\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 2s 216ms/step - loss: 0.6747 - accuracy: 0.6087\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 2s 237ms/step - loss: 0.6639 - accuracy: 0.6479\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 2s 235ms/step - loss: 0.6508 - accuracy: 0.6720\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 2s 287ms/step - loss: 0.6424 - accuracy: 0.6722\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 2s 265ms/step - loss: 0.6283 - accuracy: 0.7094\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 2s 290ms/step - loss: 0.5967 - accuracy: 0.7264\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 2s 323ms/step - loss: 0.5610 - accuracy: 0.7675\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 2s 274ms/step - loss: 0.5588 - accuracy: 0.7585\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 2s 287ms/step - loss: 0.5101 - accuracy: 0.8100\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 2s 285ms/step - loss: 0.4936 - accuracy: 0.8268\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 2s 319ms/step - loss: 0.5033 - accuracy: 0.8095\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 2s 324ms/step - loss: 0.5067 - accuracy: 0.8052\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 3s 382ms/step - loss: 0.4529 - accuracy: 0.8609\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 2s 304ms/step - loss: 0.4636 - accuracy: 0.8495\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 2s 287ms/step - loss: 0.4712 - accuracy: 0.8409\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 2s 269ms/step - loss: 0.4693 - accuracy: 0.8430\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 2s 239ms/step - loss: 0.4524 - accuracy: 0.8613\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 2s 237ms/step - loss: 0.4427 - accuracy: 0.8706\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 2s 236ms/step - loss: 0.4474 - accuracy: 0.8653\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 2s 237ms/step - loss: 0.4836 - accuracy: 0.8291\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 2s 242ms/step - loss: 0.4526 - accuracy: 0.8589\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 2s 242ms/step - loss: 0.4517 - accuracy: 0.8597\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 2s 246ms/step - loss: 0.4687 - accuracy: 0.8427\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 2s 245ms/step - loss: 0.4761 - accuracy: 0.8357\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 2s 244ms/step - loss: 0.4671 - accuracy: 0.8449\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 2s 250ms/step - loss: 0.4872 - accuracy: 0.8247\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 2s 234ms/step - loss: 0.4749 - accuracy: 0.8369\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 2s 230ms/step - loss: 0.5190 - accuracy: 0.7924\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 2s 219ms/step - loss: 0.6159 - accuracy: 0.6952\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 2s 229ms/step - loss: 0.6054 - accuracy: 0.7050\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 2s 220ms/step - loss: 0.5827 - accuracy: 0.7279\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 2s 217ms/step - loss: 0.5762 - accuracy: 0.7339\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 2s 217ms/step - loss: 0.5650 - accuracy: 0.7453\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 2s 220ms/step - loss: 0.5508 - accuracy: 0.7593\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 2s 224ms/step - loss: 0.5498 - accuracy: 0.7605\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 2s 225ms/step - loss: 0.5620 - accuracy: 0.7478\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 2s 225ms/step - loss: 0.5801 - accuracy: 0.7304\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 2s 230ms/step - loss: 0.5774 - accuracy: 0.7332\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 2s 230ms/step - loss: 0.5714 - accuracy: 0.7384\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 1s 212ms/step - loss: 0.5733 - accuracy: 0.7367\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 1s 211ms/step - loss: 0.5527 - accuracy: 0.7573\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 2s 247ms/step - loss: 0.5547 - accuracy: 0.7552\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 2s 302ms/step - loss: 0.5500 - accuracy: 0.7598\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 2s 214ms/step - loss: 0.5447 - accuracy: 0.7658\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 2s 223ms/step - loss: 0.5427 - accuracy: 0.7671\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 2s 250ms/step - loss: 0.5321 - accuracy: 0.7778\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 2s 263ms/step - loss: 0.5468 - accuracy: 0.7632\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 2s 238ms/step - loss: 0.5408 - accuracy: 0.7692\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 2s 212ms/step - loss: 0.5364 - accuracy: 0.7735\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 2s 245ms/step - loss: 0.5309 - accuracy: 0.7793\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 1s 194ms/step - loss: 0.5291 - accuracy: 0.7814\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 1s 193ms/step - loss: 0.5181 - accuracy: 0.7925\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 1s 191ms/step - loss: 0.5163 - accuracy: 0.7942\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 1s 192ms/step - loss: 0.5114 - accuracy: 0.7991\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 2s 220ms/step - loss: 0.5141 - accuracy: 0.7965\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 2s 320ms/step - loss: 0.5122 - accuracy: 0.7985\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 2s 230ms/step - loss: 0.5200 - accuracy: 0.7904\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 2s 242ms/step - loss: 0.5110 - accuracy: 0.7997\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 1s 208ms/step - loss: 0.5085 - accuracy: 0.8022\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 2s 227ms/step - loss: 0.4880 - accuracy: 0.8226\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 1s 206ms/step - loss: 0.4888 - accuracy: 0.8220\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 2s 255ms/step - loss: 0.4827 - accuracy: 0.8284\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 2s 292ms/step - loss: 0.4820 - accuracy: 0.8291\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 2s 294ms/step - loss: 0.4867 - accuracy: 0.8245\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 2s 245ms/step - loss: 0.4671 - accuracy: 0.8445\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 1s 208ms/step - loss: 0.4692 - accuracy: 0.8425\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 2s 220ms/step - loss: 0.4614 - accuracy: 0.8502\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 2s 266ms/step - loss: 0.4558 - accuracy: 0.8558\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 2s 228ms/step - loss: 0.4704 - accuracy: 0.8414\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 2s 238ms/step - loss: 0.4632 - accuracy: 0.8481\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 2s 221ms/step - loss: 0.4609 - accuracy: 0.8509\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 2s 293ms/step - loss: 0.4525 - accuracy: 0.8594\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 5s 729ms/step - loss: 0.4675 - accuracy: 0.8442\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 3s 473ms/step - loss: 0.4556 - accuracy: 0.8555\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 3s 440ms/step - loss: 0.4654 - accuracy: 0.8463\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 4s 476ms/step - loss: 0.4646 - accuracy: 0.8474\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.4530 - accuracy: 0.8587\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 4s 615ms/step - loss: 0.4707 - accuracy: 0.8409\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 3s 369ms/step - loss: 0.4634 - accuracy: 0.8480\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 3s 468ms/step - loss: 0.4554 - accuracy: 0.8564\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 4s 566ms/step - loss: 0.4501 - accuracy: 0.8613\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 4s 630ms/step - loss: 0.4468 - accuracy: 0.8650\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 5s 680ms/step - loss: 0.4546 - accuracy: 0.8575\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 5s 717ms/step - loss: 0.4429 - accuracy: 0.8691\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 5s 700ms/step - loss: 0.4435 - accuracy: 0.8686\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 4s 526ms/step - loss: 0.4587 - accuracy: 0.8532\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 3s 470ms/step - loss: 0.4637 - accuracy: 0.8481\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 4s 558ms/step - loss: 0.4475 - accuracy: 0.8645\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 3s 467ms/step - loss: 0.4448 - accuracy: 0.8671\n"
     ]
    }
   ],
   "source": [
    "# silence vs audio training\n",
    "x_silence = readDir('C:/Users/HP/Documents/test/no-audio', 16000) \n",
    "x_speech =  readDir('C:/Users/HP/Documents/test/audio', 16000)\n",
    "\n",
    "\n",
    "X = np.concatenate((x_silence, x_speech))\n",
    "y_silence = np.load('file_path') #File  Containing framewise labels of all samples\n",
    "y_speech = np.load('file_path') #File  Containing framewise labels of all samples\n",
    "Y = np.concatenate((y_silence, y_speech))\n",
    "\n",
    "X=audio2mfcc(X,20, 16000)\n",
    "\n",
    "lis=[]\n",
    "for i in range(0,len(Y)):\n",
    "    lis.append( np.array(  [[Y[i][0], Y[i][1]]]* len(X[1]) )  )\n",
    "Y=np.array(lis)\n",
    "\n",
    "X_train, X_validation, X_test, y_train, y_validation, y_test = prepare_datasets(X,Y,0.25, 0.2)\n",
    "input_shape = (X.shape[1], X.shape[2])\n",
    "\n",
    "\n",
    "model1=Classifier()\n",
    "model1.rnn(X, Y, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 3s 172ms/step - loss: 0.7868 - accuracy: 0.5049\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 1s 169ms/step - loss: 0.7911 - accuracy: 0.5003\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 1s 177ms/step - loss: 0.7111 - accuracy: 0.5915\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 1s 203ms/step - loss: 0.6907 - accuracy: 0.6076\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 0.6743 - accuracy: 0.6311\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 1s 178ms/step - loss: 0.6766 - accuracy: 0.6328\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 1s 178ms/step - loss: 0.6721 - accuracy: 0.6363\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 1s 173ms/step - loss: 0.6741 - accuracy: 0.6360\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 0.6781 - accuracy: 0.6354\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 1s 171ms/step - loss: 0.6772 - accuracy: 0.6362\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 1s 171ms/step - loss: 0.6763 - accuracy: 0.6357\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 1s 169ms/step - loss: 0.6731 - accuracy: 0.6368\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 1s 170ms/step - loss: 0.6729 - accuracy: 0.6366\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 1s 178ms/step - loss: 0.6741 - accuracy: 0.6366\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 0.6746 - accuracy: 0.6363\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 1s 173ms/step - loss: 0.6746 - accuracy: 0.6362\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 1s 173ms/step - loss: 0.6760 - accuracy: 0.6363\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 0.6755 - accuracy: 0.6369\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 1s 175ms/step - loss: 0.6732 - accuracy: 0.6365\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 1s 171ms/step - loss: 0.6715 - accuracy: 0.6369\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 0.6742 - accuracy: 0.6359\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 1s 169ms/step - loss: 0.6738 - accuracy: 0.6363\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 1s 170ms/step - loss: 0.6735 - accuracy: 0.6366\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 1s 170ms/step - loss: 0.6773 - accuracy: 0.6366\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 0.6759 - accuracy: 0.6364\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 1s 173ms/step - loss: 0.6740 - accuracy: 0.6363\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 1s 171ms/step - loss: 0.6763 - accuracy: 0.6363\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 1s 170ms/step - loss: 0.6758 - accuracy: 0.6360\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 0.6730 - accuracy: 0.6371\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 0.6783 - accuracy: 0.6364\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 1s 178ms/step - loss: 0.6729 - accuracy: 0.6371\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 1s 282ms/step - loss: 0.6759 - accuracy: 0.6359\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 1s 189ms/step - loss: 0.6754 - accuracy: 0.6363\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 1s 305ms/step - loss: 0.6760 - accuracy: 0.6363\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 1s 180ms/step - loss: 0.6728 - accuracy: 0.6372\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 1s 174ms/step - loss: 0.6742 - accuracy: 0.6357\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 0.6722 - accuracy: 0.6361\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 1s 176ms/step - loss: 0.6735 - accuracy: 0.6368\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 1s 177ms/step - loss: 0.6724 - accuracy: 0.6360\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 1s 175ms/step - loss: 0.6725 - accuracy: 0.6360\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 1s 184ms/step - loss: 0.6733 - accuracy: 0.6361\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 1s 319ms/step - loss: 0.6727 - accuracy: 0.6369\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 1s 322ms/step - loss: 0.6756 - accuracy: 0.6361\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 1s 306ms/step - loss: 0.6727 - accuracy: 0.6360\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 1s 300ms/step - loss: 0.6714 - accuracy: 0.6364\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 1s 305ms/step - loss: 0.6743 - accuracy: 0.6368\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 1s 308ms/step - loss: 0.6720 - accuracy: 0.6359\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.6707 - accuracy: 0.6365\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 2s 392ms/step - loss: 0.6716 - accuracy: 0.6368\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 2s 386ms/step - loss: 0.6726 - accuracy: 0.6358\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 2s 514ms/step - loss: 0.6745 - accuracy: 0.6361\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 2s 480ms/step - loss: 0.6721 - accuracy: 0.6366\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 2s 451ms/step - loss: 0.6745 - accuracy: 0.6362\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 2s 346ms/step - loss: 0.6737 - accuracy: 0.6363\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 1s 365ms/step - loss: 0.6731 - accuracy: 0.6370\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 1s 329ms/step - loss: 0.6710 - accuracy: 0.6367\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 2s 410ms/step - loss: 0.6701 - accuracy: 0.6362\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 2s 454ms/step - loss: 0.6742 - accuracy: 0.6362\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 2s 399ms/step - loss: 0.6718 - accuracy: 0.6361\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 2s 473ms/step - loss: 0.6729 - accuracy: 0.6370\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 2s 384ms/step - loss: 0.6736 - accuracy: 0.6362\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 2s 397ms/step - loss: 0.6719 - accuracy: 0.6369\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 1s 322ms/step - loss: 0.6707 - accuracy: 0.6368\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 3s 726ms/step - loss: 0.6712 - accuracy: 0.6370\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 2s 554ms/step - loss: 0.6719 - accuracy: 0.6368\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 2s 555ms/step - loss: 0.6721 - accuracy: 0.6360\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 3s 748ms/step - loss: 0.6719 - accuracy: 0.6366\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 2s 553ms/step - loss: 0.6724 - accuracy: 0.6359\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 2s 586ms/step - loss: 0.6710 - accuracy: 0.6359\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 2s 443ms/step - loss: 0.6703 - accuracy: 0.6362\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 2s 388ms/step - loss: 0.6709 - accuracy: 0.6373\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 1s 367ms/step - loss: 0.6699 - accuracy: 0.6368\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 2s 395ms/step - loss: 0.6724 - accuracy: 0.6371\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 2s 356ms/step - loss: 0.6701 - accuracy: 0.6364\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 1s 349ms/step - loss: 0.6708 - accuracy: 0.6367\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 1s 394ms/step - loss: 0.6687 - accuracy: 0.6361\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 2s 491ms/step - loss: 0.6711 - accuracy: 0.6368\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 1s 349ms/step - loss: 0.6700 - accuracy: 0.6362\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 2s 492ms/step - loss: 0.6702 - accuracy: 0.6374\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 2s 504ms/step - loss: 0.6697 - accuracy: 0.6361\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 2s 484ms/step - loss: 0.6685 - accuracy: 0.6369\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 2s 521ms/step - loss: 0.6676 - accuracy: 0.6379\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 625ms/step - loss: 0.6667 - accuracy: 0.6370\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 2s 374ms/step - loss: 0.6644 - accuracy: 0.6379\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 2s 426ms/step - loss: 0.6650 - accuracy: 0.6371\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 3s 800ms/step - loss: 0.6649 - accuracy: 0.6378\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 2s 331ms/step - loss: 0.6632 - accuracy: 0.6386\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 1s 309ms/step - loss: 0.6613 - accuracy: 0.6378\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 1s 251ms/step - loss: 0.6624 - accuracy: 0.6375\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 1s 270ms/step - loss: 0.6584 - accuracy: 0.6388\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 0.6549 - accuracy: 0.6393\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 0.6515 - accuracy: 0.6434\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 1s 209ms/step - loss: 0.6506 - accuracy: 0.6417\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 0.6504 - accuracy: 0.6417\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 1s 203ms/step - loss: 0.6449 - accuracy: 0.6412\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 1s 204ms/step - loss: 0.6422 - accuracy: 0.6480\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 2s 411ms/step - loss: 0.6358 - accuracy: 0.6544\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 2s 374ms/step - loss: 0.6334 - accuracy: 0.6572\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 2s 483ms/step - loss: 0.6336 - accuracy: 0.6641\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 2s 481ms/step - loss: 0.6215 - accuracy: 0.6725\n"
     ]
    }
   ],
   "source": [
    "# speech vs music training\n",
    "x_speech = readDir('C:/Users/HP/Documents/test/speech', 16000)\n",
    "x_music = readDir('C:/Users/HP/Documents/test/music', 16000) \n",
    "X = np.concatenate((x_speech, x_music))\n",
    "y_speech = np.array([[1,0]]*len(x_speech))\n",
    "y_music= np.array([[0,1]]*len(x_music))\n",
    "Y = np.concatenate((y_speech, y_music))\n",
    "\n",
    "X=audio2mfcc(X,20, 16000)\n",
    "\n",
    "lis=[]\n",
    "for i in range(0,len(Y)):\n",
    "    lis.append( np.array(  [[Y[i][0], Y[i][1]]]* len(X[1]) )  )\n",
    "Y=np.array(lis)\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_validation, X_test, y_train, y_validation, y_test = prepare_datasets(X,Y,0.25, 0.2)\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "#X=X_train\n",
    "\n",
    "model2=Classifier()\n",
    "model2.rnn(X_train, y_train,input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  audio vs no audio prediction\n",
    "\n",
    "data = readDir('C:/Users/HP/Documents/test/unknown/', 16000) # This will work for single file in folder. For multiple files, WE can run this in a loop for every unknown audio file in folder\n",
    "data=audio2mfcc(data)\n",
    "pred= model1.model.predict(data)\n",
    "\n",
    "\n",
    "p=np.ones((len(X[1]),2))\n",
    "\n",
    "for i in range(0, len(X[1])):\n",
    "    if(pred[0][i][1]>0.5):\n",
    "        p[i][0]=0\n",
    "        p[i][1]=1\n",
    "    else:\n",
    "        p[i][0]=1\n",
    "        p[i][1]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.32 , 8.672],\n",
       "       [0.   , 0.   ],\n",
       "       [0.   , 0.   ],\n",
       "       [0.   , 0.   ],\n",
       "       [0.   , 0.   ],\n",
       "       [0.   , 0.   ]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Time label prediction\n",
    "\n",
    "k=0\n",
    "j=0\n",
    "sil=np.array([[0.0,0.0],[0.0,0.0],[0.0,0.0],[0.0,0.0],[0.0,0.0],[0.0,0.0]])\n",
    "sp=np.array([[0.0,0.0],[0.0,0.0],[0.0,0.0],[0.0,0.0],[0.0,0.0],[0.0,0.0]])\n",
    "\n",
    "def check(x):\n",
    "    sum=0\n",
    "    for i in range(0,len(x)):\n",
    "        sum=sum+x[i][0]\n",
    "    if(sum>=10):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "    \n",
    "prev=1\n",
    "\n",
    "for i in range(0,len(p)-16):\n",
    "    x=p[i:i+16]\n",
    "    a=check(x)\n",
    "    #print(a)\n",
    "    if(a==1):\n",
    "        if(prev==1):\n",
    "            sil[j][1]=librosa.frames_to_time(i+22, sr=16000, hop_length=512, n_fft=1024)\n",
    "        else:\n",
    "            temp=i\n",
    "            while(p[i][0]!=1):\n",
    "                i+=1\n",
    "            sp[k][1]=librosa.frames_to_time(i, sr=16000, hop_length=512, n_fft=1024)\n",
    "            sil[j][0]=librosa.frames_to_time(i, sr=16000, hop_length=512, n_fft=1024)\n",
    "            sil[j][1]=librosa.frames_to_time(temp+22, sr=16000, hop_length=512, n_fft=1024)\n",
    "            k+=1\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        if(prev==1):\n",
    "            temp=i\n",
    "            while(p[i][1]!=1):\n",
    "                i+=1\n",
    "            sil[j][1]=librosa.frames_to_time(i, sr=16000, hop_length=512, n_fft=1024)\n",
    "            sp[k][0]=librosa.frames_to_time(i, sr=16000, hop_length=512, n_fft=1024)\n",
    "            sp[k][1]=librosa.frames_to_time(temp+22, sr=16000, hop_length=512, n_fft=1024)\n",
    "            j+=1\n",
    "        \n",
    "        else:\n",
    "            sp[k][1]=librosa.frames_to_time(i+22, sr=16000, hop_length=512, n_fft=1024)\n",
    "    prev=a      \n",
    "\n",
    "    \n",
    "sp  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259 270\n"
     ]
    }
   ],
   "source": [
    "#Extracting audio portions\n",
    "\n",
    "lis=[]\n",
    "for i in range(len(sp)):\n",
    "    if(sp[i][0]==0 and sp[i][1]==0):\n",
    "        continue\n",
    "    else:\n",
    "        lis.append(np.array([sp[i][0],sp[i][1]]))\n",
    "sp=np.array(lis)\n",
    "\n",
    "\n",
    "lis=[]\n",
    "for i in range(0,len(sp)):\n",
    "    start= librosa.time_to_frames(sp[i][0], sr=16000, hop_length=512, n_fft=1024)\n",
    "    end = librosa.time_to_frames(sp[i][1], sr=16000, hop_length=512, n_fft=1024)\n",
    "    print(start,end)\n",
    "    temp= np.array(data[0][start:end])\n",
    "    temp = temp[ np.newaxis, ...]\n",
    "    lis.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 60)\n",
      "8.32 8.672 music\n"
     ]
    }
   ],
   "source": [
    "frame_pred= predict_framewise(model2,lis)\n",
    "#print(len(frame_pred))\n",
    "agg=predict_aggregate(frame_pred)  \n",
    "\n",
    "for i in range(len(sp)):\n",
    "    print(sp[i][0],sp[i][1], 'speech' if (agg[i][0]==1) else  'music')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
