{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that here testing is done on .wav files. For testing on spectrogram , the readDir function can be changed accordingly. However here too, the MFCC features are calculated from decibel power spectrum only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import log, dot, e\n",
    "import librosa\n",
    "from numpy.random import rand\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(X, t, testFraction=0.2, randomize = False):\n",
    "    \"\"\"\n",
    "    Split the data randomly into training and test sets\n",
    "    Use numpy functions only\n",
    "    Inputs:\n",
    "        X: (np array of len Nclips) input feature vectors\n",
    "        t: (np array of len Nclips) targets; one hot vectors\n",
    "        testFraction: (float) Nclips_test = testFraction * Nclips\n",
    "    Outputs:\n",
    "        X_train: training set\n",
    "        X_test: test set\n",
    "        t_train: training labels\n",
    "        t_test: test labels\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 5 MARKS\n",
    "\n",
    "    \n",
    "    test_samples = (int) (len(X)*testFraction )\n",
    "    \n",
    "    temp=np.arange(len(X))\n",
    "    np.random.shuffle(temp)\n",
    "    \n",
    "    \n",
    "    temp1 = temp[0: test_samples]\n",
    "    temp2 = temp[test_samples: len(X)]\n",
    "    \n",
    "   \n",
    "    \n",
    "    X_test = np.reshape(X[temp1[0]],(-1,1))\n",
    "    X_test = np.transpose(X_test)\n",
    "    \n",
    "    t_test = np.reshape(t[temp1[0]],(-1,1))\n",
    "    t_test = np.transpose(t_test)\n",
    "    for x in range(1,len(temp1)):\n",
    "        i=temp1[x]\n",
    "        a=np.reshape(X[i],(-1,1))\n",
    "        a=np.transpose(a)\n",
    "        b=np.reshape(t[i],(-1,1))\n",
    "        b=np.transpose(b)\n",
    "        X_test = np.concatenate((X_test,a))\n",
    "        t_test = np.concatenate((t_test,b))\n",
    "        \n",
    "    X_train = np.reshape(X[temp2[0]],(-1,1))\n",
    "    X_train = np.transpose(X_train)\n",
    "    \n",
    "    t_train = np.reshape(t[temp2[0]],(-1,1))\n",
    "    t_train = np.transpose(t_train)\n",
    "    for x in range(1,len(temp2)):\n",
    "        i=temp2[x]\n",
    "        a=np.reshape(X[i],(-1,1))\n",
    "        a=np.transpose(a)\n",
    "        b=np.reshape(t[i],(-1,1))\n",
    "        b=np.transpose(b)\n",
    "        X_train = np.concatenate((X_train,a))\n",
    "        t_train = np.concatenate((t_train,b))\n",
    "        \n",
    "    return X_train, t_train, X_test, t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_framewise(model,x_test):\n",
    "        '''\n",
    "        Framewise classification (speech or music)\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        \n",
    "        lis=[]   \n",
    "\n",
    "        \n",
    "        for i in range(0,len(x_test)):\n",
    "            \n",
    "            \n",
    "            temp =np.ones((1,2))\n",
    "            #print(x_test[i].shape)\n",
    "            \n",
    "            temp1=[]\n",
    "            for l in range(0,len(x_test[i])):\n",
    "                temp2=x_test[i][l]\n",
    "                temp2=np.reshape(temp2,(1,60))\n",
    "                temp1.append(temp2)\n",
    "            data=np.array(temp1)\n",
    "\n",
    "            data = data[..., np.newaxis]\n",
    "            \n",
    "            \n",
    "            feat_4 = model.model.predict(data)\n",
    "            \n",
    "            \n",
    "                \n",
    "                \n",
    "            for j in range(0,len(feat_4)):   \n",
    "                \n",
    "                if(feat_4[j][0] > 0.5):\n",
    "                    temp = np.concatenate( (temp, np.transpose(np.reshape([1,0] , (-1,1) ) ) ) ) \n",
    "                else:\n",
    "                    temp = np.concatenate((temp, np.transpose(np.reshape([0,1] , (-1,1) ) ) ) ) \n",
    "                    \n",
    "            #print(temp.shape)\n",
    "                    \n",
    "            temp = temp[1:]\n",
    "            \n",
    "                \n",
    "            \n",
    "            lis.append(temp)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        return lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_aggregate(y_pred_framewise):\n",
    "        '''\n",
    "        Aggregate frames to give a single class label (music or speech) to the entire audio file\n",
    "        Input:\n",
    "            y_pred_framewise = framewise prediction\n",
    "        Output:\n",
    "            y_hat = frame aggregate (one-hot vectors)\n",
    "            \n",
    "        '''\n",
    "       \n",
    "\n",
    "        \n",
    "        y_hat= np.ones((1,2))\n",
    "        for i in range (0,len(y_pred_framewise)):\n",
    "            \n",
    "            zero=0\n",
    "            one=0\n",
    "            t=y_pred_framewise[i]\n",
    "            for j in range(0, len(t)):\n",
    "                \n",
    "                if(t[j][0] == 1):\n",
    "                    one+=1\n",
    "                else:\n",
    "                    zero+=1\n",
    "            if(one>zero):\n",
    "                y_hat= np.concatenate((y_hat, np.transpose(np.reshape([1,0] , (-1,1) ) ) )) \n",
    "                \n",
    "            else:\n",
    "                y_hat= np.concatenate((y_hat, np.transpose(np.reshape([0,1] , (-1,1) ) ) ))  \n",
    "\n",
    "        \n",
    "\n",
    "        y_hat=y_hat[1:]\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "def readDir(dirname, Fs = 16000):\n",
    "    \n",
    "    '''\n",
    "    This function reads all training samples, find thier power spectrogram, convert power spectrogram to mfcc features and \n",
    "    concatenate all frames of all samples along rows. Hence output matrix is frames X n_mfcc\n",
    "    '''  \n",
    "\n",
    "\n",
    "    no_samp_in_10_sec = 10* Fs\n",
    "    files = glob(dirname + '/*.wav')\n",
    "    x= np.ones((1,60))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for f in files:\n",
    "    \n",
    "        \n",
    "        samples = load_audio(f,Fs)\n",
    "        n_fft = 1024\n",
    "        hop_length = 512\n",
    "        win_length = 1024\n",
    "        X = np.abs(librosa.stft(samples, n_fft = n_fft, hop_length = hop_length, win_length = win_length, window='hann'))\n",
    "        X = librosa.power_to_db(X**2,ref=np.max)\n",
    "        \n",
    "        temp =pow(10,X/10) \n",
    "        mel_spectrogram = librosa.feature.melspectrogram(y='none',S=temp, sr=16000, n_fft=n_fft, hop_length=hop_length, n_mels=21,win_length = win_length, window='hann')\n",
    "        log_mel_spectrogram = librosa.power_to_db(mel_spectrogram)\n",
    "        \n",
    "        \n",
    "        mfccs = librosa.feature.mfcc(y='none',S=log_mel_spectrogram, n_mfcc=21, sr=16000,hop_length = hop_length, win_length = win_length ,n_fft=n_fft,window='hann')\n",
    "        mfccs= mfccs[1:]\n",
    "        #print(mfccs.shape)\n",
    "        delta_mfccs = librosa.feature.delta(mfccs)\n",
    "        delta2_mfccs = librosa.feature.delta(mfccs, order=2)\n",
    "        mfccs=np.concatenate((mfccs,delta_mfccs))\n",
    "        mfccs=np.concatenate((mfccs,delta2_mfccs))\n",
    "        mfccs=np.array(mfccs)\n",
    "        \n",
    "        mfccs=np.transpose(mfccs)\n",
    "        x=np.concatenate((x,mfccs))\n",
    "    \n",
    "    #print(k)\n",
    "    \n",
    "    return x[1:]\n",
    "\n",
    "\n",
    "    return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(filename, Fs = 16000):\n",
    "    '''\n",
    "    Inputs: \n",
    "        filename: (str) filename\n",
    "        Fs: (int) sampling rate\n",
    "    Output: \n",
    "        x: 1D np array \n",
    "    '''\n",
    "    \n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 2 MARKS\n",
    "\n",
    "    x,sr=librosa.load(filename,sr=Fs)\n",
    "    x=np.array(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(X,y,test_size, validation_size):\n",
    "\n",
    "    \n",
    "\n",
    "    # load data\n",
    "    \n",
    "\n",
    "    # create train, validation and test split\n",
    "    X_train,  y_train, X_test, y_test = splitData(X, y, 0.2)\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    #X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validation_size)\n",
    "    X_train, y_train, X_validation, y_validation = splitData(X_train,y_train,0.1)\n",
    "    # add an axis to input sets\n",
    "    X_train = X_train[..., np.newaxis]\n",
    "    X_validation = X_validation[..., np.newaxis]\n",
    "    X_test = X_test[..., np.newaxis]\n",
    "\n",
    "    return X_train, X_validation, X_test, y_train, y_validation, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio2mfcc(x, n_mfcc = 20, Fs = 16000):\n",
    "    \n",
    "    '''\n",
    "    Compute Mel-frequency cepstral coefficients (MFCCs)\n",
    "    Inputs:\n",
    "        x: np array of shape (Nclips,)\n",
    "        Fs: (int) sampling rate\n",
    "        n_mfcc: (int) number of MFCC features\n",
    "    Output:\n",
    "        X: (np array) MFCC sequence\n",
    "    '''\n",
    "\n",
    "  \n",
    "    \n",
    "   \n",
    "    lis=[]\n",
    "    if(len(x.shape) <=1):\n",
    "        x= np.reshape(x, (1,len(x))) \n",
    "    \n",
    "    for i in range(0, len(x)):\n",
    "        \n",
    "        mfccs = librosa.feature.mfcc(y=x[i], n_mfcc=60, sr=Fs,n_fft=1024,hop_length = 512, win_length = 1024)\n",
    "        \n",
    "        #delta_mfccs = librosa.feature.delta(mfccs)\n",
    "        #delta2_mfccs = librosa.feature.delta(mfccs, order=2)\n",
    "        #mfccs=np.concatenate((mfccs,delta_mfccs))\n",
    "        #mfccs=np.concatenate((mfccs,delta2_mfccs))\n",
    "        #mfccs=np.array(mfccs)\n",
    "        mfccs=np.transpose(mfccs)\n",
    "        lis.append(mfccs)\n",
    "    ### WRITE YOUR CODE HERE - 3 MARKS\n",
    "    \n",
    "    X=np.array(lis)\n",
    "\n",
    "     \n",
    "\n",
    "    return X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier: \n",
    "    '''\n",
    "    Create a linear classifier to classify each frame\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.W=np.random.rand(20,)\n",
    "    \n",
    "    def sigmoid(self, z): return 1 / (1 + e**(-z))\n",
    "    \n",
    "\n",
    "   \n",
    "    \n",
    "    def cn(self,X_train, y_train,X_validation, y_validation, input_shape):\n",
    "        \n",
    "        model = keras.Sequential()\n",
    "\n",
    "            # 1st conv layer\n",
    "        model.add(keras.layers.Conv2D(32, (3, 3),padding='same' ,activation='relu', input_shape=input_shape))\n",
    "        model.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "            # 2nd conv layer\n",
    "        model.add(keras.layers.Conv2D(32, (3, 3),padding='same' , activation='relu'))\n",
    "        model.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "            # 3rd conv layer\n",
    "        model.add(keras.layers.Conv2D(32, (2, 2), padding='same' ,activation='relu'))\n",
    "        model.add(keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "            # flatten output and feed it into dense layer\n",
    "        model.add(keras.layers.Flatten())\n",
    "\n",
    "        model.add(keras.layers.Dense(256, activation='relu'))\n",
    "        model.add(keras.layers.Dropout(0.3))\n",
    "\n",
    "        model.add(keras.layers.Dense(192, activation='relu'))\n",
    "        model.add(keras.layers.Dropout(0.3))\n",
    "\n",
    "        model.add(keras.layers.Dense(128, activation='relu'))\n",
    "        model.add(keras.layers.Dropout(0.3))\n",
    "\n",
    "        model.add(keras.layers.Dense(64, activation='relu'))\n",
    "        model.add(keras.layers.Dropout(0.3))\n",
    "\n",
    "            # output layer\n",
    "        model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "\n",
    "        model.compile(optimizer='adam', loss=tf.losses.CategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "        model.fit(X_train, y_train, validation_data=(X_validation, y_validation), batch_size=32, epochs=100)\n",
    "        \n",
    "    \n",
    "        \n",
    "        self.model=model\n",
    "\n",
    "    \n",
    "    \n",
    "    def save_model(self, save_path):\n",
    "        '''\n",
    "        Save the trained model on local disk\n",
    "        Input:\n",
    "            save_path: location at which model is to be saved\n",
    "        Output:\n",
    "            None\n",
    "            \n",
    "        '''\n",
    "        ## Assuming save_path contains the file name too. If save_path contains only directory\n",
    "        ## name , uncomment the below line to save file as data.npy\n",
    "        \n",
    "        #save_path = save_path +'/data'\n",
    "        \n",
    "        data=self.W\n",
    "        np.save(save_path, data)\n",
    "        \n",
    "        ### WRITE YOUR CODE HERE - 0 MARKS\n",
    "            \n",
    "        return\n",
    "    \n",
    "    def load_model(self, load_path):\n",
    "        '''\n",
    "        Save the trained model on local disk\n",
    "        Input:\n",
    "            load_path: location from which model is to be loaded\n",
    "        Output:\n",
    "            None\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        ### WRITE YOUR CODE HERE - 0 MARKS\n",
    "        \n",
    "        ## Assuming load_path also contains the name of file which has to be loaded. If load_path only contains the\n",
    "        ## directory name, uncomment the below line and replace data.npy with file name.\n",
    "        \n",
    "        #load_path = load_path +'/data.npy'\n",
    "        \n",
    "        self.W = np.load(load_path)\n",
    "            \n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCM(y, y_hat):\n",
    "    '''\n",
    "    Compute confusion matrix to evaluate your model\n",
    "    Inputs:\n",
    "        y = labels \n",
    "        y_hat = predicted output\n",
    "    Output:\n",
    "        confusion matrix: confusion matrix\n",
    "    '''\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    metrics = np.array([[0,0], [0,0]])\n",
    "\n",
    "    \n",
    "    for i in range(0,len(y)):\n",
    "        if(y[i][0] == 1 and y_hat[i][0] == 1):\n",
    "            metrics[0][0]+=1\n",
    "        elif(y[i][0] == 1 and y_hat[i][0] == 0):\n",
    "            metrics[0][1] +=1\n",
    "        elif(y[i][0] == 0 and y_hat[i][0] == 1):\n",
    "            metrics[1][0] +=1\n",
    "        else:\n",
    "            metrics[1][1]+=1\n",
    "\n",
    "    confusion_matrix = metrics\n",
    "    return confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend.py:4847: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  '\"`categorical_crossentropy` received `from_logits=True`, but '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1368/1368 [==============================] - 35s 24ms/step - loss: 0.1320 - accuracy: 0.9569 - val_loss: 0.1151 - val_accuracy: 0.9586\n",
      "Epoch 2/100\n",
      "1368/1368 [==============================] - 42s 31ms/step - loss: 0.1045 - accuracy: 0.9659 - val_loss: 0.0963 - val_accuracy: 0.9699\n",
      "Epoch 3/100\n",
      "1368/1368 [==============================] - 36s 26ms/step - loss: 0.0909 - accuracy: 0.9704 - val_loss: 0.1012 - val_accuracy: 0.9723\n",
      "Epoch 4/100\n",
      "1368/1368 [==============================] - 38s 28ms/step - loss: 0.0870 - accuracy: 0.9715 - val_loss: 0.1039 - val_accuracy: 0.9611\n",
      "Epoch 5/100\n",
      "1368/1368 [==============================] - 38s 28ms/step - loss: 0.0793 - accuracy: 0.9759 - val_loss: 0.1378 - val_accuracy: 0.9496\n",
      "Epoch 6/100\n",
      "1368/1368 [==============================] - 36s 27ms/step - loss: 0.0747 - accuracy: 0.9759 - val_loss: 0.5180 - val_accuracy: 0.7334\n",
      "Epoch 7/100\n",
      "1368/1368 [==============================] - 43s 32ms/step - loss: 0.0708 - accuracy: 0.9782 - val_loss: 0.0834 - val_accuracy: 0.9689\n",
      "Epoch 8/100\n",
      "1368/1368 [==============================] - 36s 26ms/step - loss: 0.0654 - accuracy: 0.9797 - val_loss: 0.0725 - val_accuracy: 0.9781\n",
      "Epoch 9/100\n",
      "1368/1368 [==============================] - 36s 26ms/step - loss: 0.0645 - accuracy: 0.9800 - val_loss: 0.0902 - val_accuracy: 0.9697\n",
      "Epoch 10/100\n",
      "1368/1368 [==============================] - 41s 30ms/step - loss: 0.0609 - accuracy: 0.9811 - val_loss: 0.1586 - val_accuracy: 0.9585\n",
      "Epoch 11/100\n",
      "1368/1368 [==============================] - 34s 25ms/step - loss: 0.0627 - accuracy: 0.9807 - val_loss: 0.0788 - val_accuracy: 0.9725\n",
      "Epoch 12/100\n",
      "1368/1368 [==============================] - 39s 29ms/step - loss: 0.0571 - accuracy: 0.9824 - val_loss: 0.1924 - val_accuracy: 0.9560\n",
      "Epoch 13/100\n",
      "1368/1368 [==============================] - 43s 32ms/step - loss: 0.0580 - accuracy: 0.9822 - val_loss: 0.1001 - val_accuracy: 0.9675\n",
      "Epoch 14/100\n",
      "1368/1368 [==============================] - 33s 24ms/step - loss: 0.0556 - accuracy: 0.9833 - val_loss: 0.0699 - val_accuracy: 0.9752\n",
      "Epoch 15/100\n",
      "1368/1368 [==============================] - 38s 27ms/step - loss: 0.0553 - accuracy: 0.9837 - val_loss: 0.0832 - val_accuracy: 0.9781\n",
      "Epoch 16/100\n",
      "1368/1368 [==============================] - 37s 27ms/step - loss: 0.0477 - accuracy: 0.9849 - val_loss: 0.2469 - val_accuracy: 0.9369\n",
      "Epoch 17/100\n",
      "1368/1368 [==============================] - 34s 25ms/step - loss: 0.0478 - accuracy: 0.9854 - val_loss: 0.0670 - val_accuracy: 0.9759\n",
      "Epoch 18/100\n",
      "1368/1368 [==============================] - 37s 27ms/step - loss: 0.0495 - accuracy: 0.9852 - val_loss: 0.0712 - val_accuracy: 0.9772\n",
      "Epoch 19/100\n",
      "1368/1368 [==============================] - 47s 34ms/step - loss: 0.0469 - accuracy: 0.9858 - val_loss: 0.1676 - val_accuracy: 0.9603\n",
      "Epoch 20/100\n",
      "1368/1368 [==============================] - 43s 31ms/step - loss: 0.0449 - accuracy: 0.9871 - val_loss: 0.1347 - val_accuracy: 0.9598\n",
      "Epoch 21/100\n",
      "1368/1368 [==============================] - 37s 27ms/step - loss: 0.0448 - accuracy: 0.9869 - val_loss: 0.0717 - val_accuracy: 0.9773\n",
      "Epoch 22/100\n",
      "1368/1368 [==============================] - 26s 19ms/step - loss: 0.0472 - accuracy: 0.9861 - val_loss: 0.0842 - val_accuracy: 0.9765\n",
      "Epoch 23/100\n",
      "1368/1368 [==============================] - 21s 15ms/step - loss: 0.0411 - accuracy: 0.9877 - val_loss: 0.0724 - val_accuracy: 0.9760\n",
      "Epoch 24/100\n",
      "1368/1368 [==============================] - 20s 15ms/step - loss: 0.0421 - accuracy: 0.9877 - val_loss: 0.0730 - val_accuracy: 0.9783\n",
      "Epoch 25/100\n",
      "1368/1368 [==============================] - 20s 15ms/step - loss: 0.0455 - accuracy: 0.9867 - val_loss: 0.1392 - val_accuracy: 0.9660\n",
      "Epoch 26/100\n",
      "1368/1368 [==============================] - 20s 15ms/step - loss: 0.0376 - accuracy: 0.9885 - val_loss: 0.0659 - val_accuracy: 0.9780\n",
      "Epoch 27/100\n",
      "1368/1368 [==============================] - 19s 14ms/step - loss: 0.0410 - accuracy: 0.9885 - val_loss: 0.0811 - val_accuracy: 0.9764\n",
      "Epoch 28/100\n",
      "1368/1368 [==============================] - 19s 14ms/step - loss: 0.0384 - accuracy: 0.9886 - val_loss: 0.1173 - val_accuracy: 0.9736\n",
      "Epoch 29/100\n",
      "1368/1368 [==============================] - 20s 15ms/step - loss: 0.0364 - accuracy: 0.9885 - val_loss: 0.1381 - val_accuracy: 0.9705\n",
      "Epoch 30/100\n",
      "1368/1368 [==============================] - 19s 14ms/step - loss: 0.0391 - accuracy: 0.9880 - val_loss: 0.0635 - val_accuracy: 0.9798\n",
      "Epoch 31/100\n",
      "1368/1368 [==============================] - 18s 13ms/step - loss: 0.0366 - accuracy: 0.9886 - val_loss: 0.0704 - val_accuracy: 0.9781\n",
      "Epoch 32/100\n",
      "1368/1368 [==============================] - 19s 14ms/step - loss: 0.0362 - accuracy: 0.9896 - val_loss: 0.0859 - val_accuracy: 0.9792\n",
      "Epoch 33/100\n",
      "1368/1368 [==============================] - 18s 13ms/step - loss: 0.0354 - accuracy: 0.9898 - val_loss: 0.0707 - val_accuracy: 0.9807\n",
      "Epoch 34/100\n",
      "1368/1368 [==============================] - 18s 13ms/step - loss: 0.0358 - accuracy: 0.9899 - val_loss: 0.0806 - val_accuracy: 0.9804\n",
      "Epoch 35/100\n",
      "1368/1368 [==============================] - 23s 17ms/step - loss: 0.0331 - accuracy: 0.9901 - val_loss: 0.1066 - val_accuracy: 0.9754\n",
      "Epoch 36/100\n",
      "1368/1368 [==============================] - 17s 13ms/step - loss: 0.0357 - accuracy: 0.9894 - val_loss: 0.0643 - val_accuracy: 0.9823\n",
      "Epoch 37/100\n",
      "1368/1368 [==============================] - 18s 13ms/step - loss: 0.0338 - accuracy: 0.9895 - val_loss: 0.1714 - val_accuracy: 0.9607\n",
      "Epoch 38/100\n",
      "1368/1368 [==============================] - 19s 14ms/step - loss: 0.0313 - accuracy: 0.9907 - val_loss: 0.0941 - val_accuracy: 0.9796\n",
      "Epoch 39/100\n",
      "1368/1368 [==============================] - 17s 13ms/step - loss: 0.0315 - accuracy: 0.9906 - val_loss: 0.1232 - val_accuracy: 0.9747\n",
      "Epoch 40/100\n",
      "1368/1368 [==============================] - 19s 14ms/step - loss: 0.0323 - accuracy: 0.9908 - val_loss: 0.1687 - val_accuracy: 0.9652\n",
      "Epoch 41/100\n",
      "1368/1368 [==============================] - 19s 14ms/step - loss: 0.0353 - accuracy: 0.9896 - val_loss: 0.0808 - val_accuracy: 0.9772\n",
      "Epoch 42/100\n",
      "1368/1368 [==============================] - 19s 14ms/step - loss: 0.0323 - accuracy: 0.9903 - val_loss: 0.0702 - val_accuracy: 0.9791\n",
      "Epoch 43/100\n",
      "1368/1368 [==============================] - 18s 13ms/step - loss: 0.0315 - accuracy: 0.9906 - val_loss: 0.0818 - val_accuracy: 0.9790\n",
      "Epoch 44/100\n",
      "1368/1368 [==============================] - 19s 14ms/step - loss: 0.0308 - accuracy: 0.9909 - val_loss: 0.0810 - val_accuracy: 0.9815\n",
      "Epoch 45/100\n",
      "1368/1368 [==============================] - 18s 13ms/step - loss: 0.0320 - accuracy: 0.9911 - val_loss: 0.0740 - val_accuracy: 0.9796\n",
      "Epoch 46/100\n",
      "1368/1368 [==============================] - 19s 14ms/step - loss: 0.0292 - accuracy: 0.9914 - val_loss: 0.0834 - val_accuracy: 0.9750\n",
      "Epoch 47/100\n",
      "1368/1368 [==============================] - 20s 15ms/step - loss: 0.0298 - accuracy: 0.9910 - val_loss: 0.0952 - val_accuracy: 0.9815\n",
      "Epoch 48/100\n",
      "1368/1368 [==============================] - 24s 18ms/step - loss: 0.0311 - accuracy: 0.9908 - val_loss: 0.0878 - val_accuracy: 0.9790\n",
      "Epoch 49/100\n",
      "1368/1368 [==============================] - 20s 15ms/step - loss: 0.0282 - accuracy: 0.9913 - val_loss: 0.1642 - val_accuracy: 0.9715\n",
      "Epoch 50/100\n",
      "1368/1368 [==============================] - 18s 13ms/step - loss: 0.0309 - accuracy: 0.9910 - val_loss: 0.0794 - val_accuracy: 0.9810\n",
      "Epoch 51/100\n",
      "1368/1368 [==============================] - 19s 14ms/step - loss: 0.0284 - accuracy: 0.9919 - val_loss: 0.0939 - val_accuracy: 0.9798\n",
      "Epoch 52/100\n",
      "1368/1368 [==============================] - 18s 13ms/step - loss: 0.0280 - accuracy: 0.9917 - val_loss: 0.1462 - val_accuracy: 0.9755\n",
      "Epoch 53/100\n",
      "1368/1368 [==============================] - 18s 13ms/step - loss: 0.0257 - accuracy: 0.9919 - val_loss: 0.0859 - val_accuracy: 0.9818\n",
      "Epoch 54/100\n",
      "1368/1368 [==============================] - 19s 14ms/step - loss: 0.0280 - accuracy: 0.9913 - val_loss: 0.0680 - val_accuracy: 0.9790\n",
      "Epoch 55/100\n",
      "1368/1368 [==============================] - 24s 17ms/step - loss: 0.0308 - accuracy: 0.9911 - val_loss: 0.3709 - val_accuracy: 0.8904\n",
      "Epoch 56/100\n",
      "1368/1368 [==============================] - 19s 14ms/step - loss: 0.0277 - accuracy: 0.9917 - val_loss: 0.0733 - val_accuracy: 0.9800\n",
      "Epoch 57/100\n",
      "1368/1368 [==============================] - 19s 14ms/step - loss: 0.0257 - accuracy: 0.9923 - val_loss: 0.0922 - val_accuracy: 0.9765\n",
      "Epoch 58/100\n",
      "1368/1368 [==============================] - 18s 13ms/step - loss: 0.0284 - accuracy: 0.9917 - val_loss: 0.0843 - val_accuracy: 0.9783\n",
      "Epoch 59/100\n",
      "1368/1368 [==============================] - 17s 12ms/step - loss: 0.0294 - accuracy: 0.9921 - val_loss: 0.0826 - val_accuracy: 0.9784\n",
      "Epoch 60/100\n",
      "1368/1368 [==============================] - 17s 12ms/step - loss: 0.0240 - accuracy: 0.9927 - val_loss: 0.1070 - val_accuracy: 0.9811\n",
      "Epoch 61/100\n",
      "1368/1368 [==============================] - 17s 13ms/step - loss: 0.0281 - accuracy: 0.9914 - val_loss: 0.1048 - val_accuracy: 0.9797\n",
      "Epoch 62/100\n",
      "1368/1368 [==============================] - 17s 12ms/step - loss: 0.0256 - accuracy: 0.9924 - val_loss: 0.0899 - val_accuracy: 0.9793\n",
      "Epoch 63/100\n",
      "1368/1368 [==============================] - 17s 12ms/step - loss: 0.0248 - accuracy: 0.9925 - val_loss: 0.1306 - val_accuracy: 0.9793\n",
      "Epoch 64/100\n",
      "1368/1368 [==============================] - 18s 13ms/step - loss: 0.0252 - accuracy: 0.9923 - val_loss: 0.0860 - val_accuracy: 0.9802\n",
      "Epoch 65/100\n",
      "1368/1368 [==============================] - 18s 13ms/step - loss: 0.0253 - accuracy: 0.9917 - val_loss: 0.0957 - val_accuracy: 0.9788\n",
      "Epoch 66/100\n",
      "1368/1368 [==============================] - 19s 14ms/step - loss: 0.0249 - accuracy: 0.9925 - val_loss: 0.1893 - val_accuracy: 0.9655\n",
      "Epoch 67/100\n",
      "1368/1368 [==============================] - 23s 17ms/step - loss: 0.0279 - accuracy: 0.9921 - val_loss: 0.1774 - val_accuracy: 0.9740\n",
      "Epoch 68/100\n",
      "1368/1368 [==============================] - 17s 12ms/step - loss: 0.0242 - accuracy: 0.9927 - val_loss: 0.1009 - val_accuracy: 0.9815\n",
      "Epoch 69/100\n",
      "1368/1368 [==============================] - 17s 12ms/step - loss: 0.0248 - accuracy: 0.9923 - val_loss: 0.0802 - val_accuracy: 0.9811\n",
      "Epoch 70/100\n",
      "1368/1368 [==============================] - 17s 12ms/step - loss: 0.0249 - accuracy: 0.9930 - val_loss: 0.1038 - val_accuracy: 0.9804\n",
      "Epoch 71/100\n",
      "1368/1368 [==============================] - 17s 12ms/step - loss: 0.0226 - accuracy: 0.9926 - val_loss: 0.1676 - val_accuracy: 0.9673\n",
      "Epoch 72/100\n",
      "1368/1368 [==============================] - 17s 12ms/step - loss: 0.0214 - accuracy: 0.9935 - val_loss: 0.0789 - val_accuracy: 0.9809\n",
      "Epoch 73/100\n",
      "1368/1368 [==============================] - 17s 12ms/step - loss: 0.0255 - accuracy: 0.9920 - val_loss: 0.1655 - val_accuracy: 0.9729\n",
      "Epoch 74/100\n",
      "1368/1368 [==============================] - 17s 12ms/step - loss: 0.0240 - accuracy: 0.9923 - val_loss: 0.1885 - val_accuracy: 0.9705\n",
      "Epoch 75/100\n",
      "1368/1368 [==============================] - 17s 12ms/step - loss: 0.0239 - accuracy: 0.9929 - val_loss: 0.1067 - val_accuracy: 0.9763\n",
      "Epoch 76/100\n",
      "1368/1368 [==============================] - 17s 12ms/step - loss: 0.0211 - accuracy: 0.9938 - val_loss: 0.0672 - val_accuracy: 0.9817\n",
      "Epoch 77/100\n",
      "1368/1368 [==============================] - 17s 12ms/step - loss: 0.0224 - accuracy: 0.9933 - val_loss: 0.0957 - val_accuracy: 0.9794\n",
      "Epoch 78/100\n",
      "1368/1368 [==============================] - 17s 13ms/step - loss: 0.0226 - accuracy: 0.9929 - val_loss: 0.1805 - val_accuracy: 0.9628\n",
      "Epoch 79/100\n",
      "1368/1368 [==============================] - 17s 12ms/step - loss: 0.0223 - accuracy: 0.9931 - val_loss: 0.1175 - val_accuracy: 0.9789\n",
      "Epoch 80/100\n",
      "1368/1368 [==============================] - 17s 12ms/step - loss: 0.0211 - accuracy: 0.9928 - val_loss: 0.1233 - val_accuracy: 0.9723\n",
      "Epoch 81/100\n",
      "1368/1368 [==============================] - 17s 13ms/step - loss: 0.0249 - accuracy: 0.9927 - val_loss: 0.1107 - val_accuracy: 0.9797\n",
      "Epoch 82/100\n",
      "1368/1368 [==============================] - 17s 12ms/step - loss: 0.0208 - accuracy: 0.9934 - val_loss: 0.1347 - val_accuracy: 0.9796\n",
      "Epoch 83/100\n",
      "1368/1368 [==============================] - 17s 13ms/step - loss: 0.0247 - accuracy: 0.9929 - val_loss: 0.1601 - val_accuracy: 0.9703\n",
      "Epoch 84/100\n",
      "1368/1368 [==============================] - 17s 12ms/step - loss: 0.0197 - accuracy: 0.9939 - val_loss: 0.0826 - val_accuracy: 0.9809\n",
      "Epoch 85/100\n",
      "1368/1368 [==============================] - 17s 12ms/step - loss: 0.0242 - accuracy: 0.9932 - val_loss: 0.0932 - val_accuracy: 0.9777\n",
      "Epoch 86/100\n",
      "1368/1368 [==============================] - 17s 12ms/step - loss: 0.0220 - accuracy: 0.9933 - val_loss: 0.1133 - val_accuracy: 0.9816\n",
      "Epoch 87/100\n",
      "1368/1368 [==============================] - 17s 12ms/step - loss: 0.0236 - accuracy: 0.9928 - val_loss: 0.0913 - val_accuracy: 0.9772\n",
      "Epoch 88/100\n",
      "1368/1368 [==============================] - 17s 12ms/step - loss: 0.0242 - accuracy: 0.9923 - val_loss: 0.0799 - val_accuracy: 0.9809\n",
      "Epoch 89/100\n",
      "1368/1368 [==============================] - 17s 13ms/step - loss: 0.0218 - accuracy: 0.9932 - val_loss: 0.1020 - val_accuracy: 0.9796\n",
      "Epoch 90/100\n",
      "1368/1368 [==============================] - 17s 12ms/step - loss: 0.0281 - accuracy: 0.9926 - val_loss: 0.0829 - val_accuracy: 0.9820\n",
      "Epoch 91/100\n",
      "1368/1368 [==============================] - 17s 13ms/step - loss: 0.0208 - accuracy: 0.9935 - val_loss: 0.1067 - val_accuracy: 0.9794\n",
      "Epoch 92/100\n",
      "1368/1368 [==============================] - 18s 13ms/step - loss: 0.0210 - accuracy: 0.9933 - val_loss: 0.1398 - val_accuracy: 0.9740\n",
      "Epoch 93/100\n",
      "1368/1368 [==============================] - 17s 12ms/step - loss: 0.0188 - accuracy: 0.9942 - val_loss: 0.1007 - val_accuracy: 0.9781\n",
      "Epoch 94/100\n",
      "1368/1368 [==============================] - 17s 12ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 0.1124 - val_accuracy: 0.9804\n",
      "Epoch 95/100\n",
      "1368/1368 [==============================] - 17s 12ms/step - loss: 0.0260 - accuracy: 0.9927 - val_loss: 0.1017 - val_accuracy: 0.9785\n",
      "Epoch 96/100\n",
      "1368/1368 [==============================] - 18s 13ms/step - loss: 0.0208 - accuracy: 0.9936 - val_loss: 0.1877 - val_accuracy: 0.9744\n",
      "Epoch 97/100\n",
      "1368/1368 [==============================] - 19s 14ms/step - loss: 0.0201 - accuracy: 0.9943 - val_loss: 0.1718 - val_accuracy: 0.9656\n",
      "Epoch 98/100\n",
      "1368/1368 [==============================] - 18s 13ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 0.1136 - val_accuracy: 0.9819\n",
      "Epoch 99/100\n",
      "1368/1368 [==============================] - 19s 14ms/step - loss: 0.0207 - accuracy: 0.9932 - val_loss: 0.1642 - val_accuracy: 0.9760\n",
      "Epoch 100/100\n",
      "1368/1368 [==============================] - 18s 13ms/step - loss: 0.0203 - accuracy: 0.9941 - val_loss: 0.2426 - val_accuracy: 0.9762\n"
     ]
    }
   ],
   "source": [
    "#silence vs audio training\n",
    "\n",
    "x_silence = readDir('C:/Users/HP/Documents/test/no-audio', 16000) \n",
    "x_speech =  readDir('C:/Users/HP/Documents/test/audio', 16000)\n",
    "X = np.concatenate((x_silence, x_speech))\n",
    "y_silence = np.array([[1,0]]*len(x_silence))\n",
    "y_speech = np.array([[0,1]]*len(x_speech))\n",
    "Y = np.concatenate((y_silence, y_speech))\n",
    "\n",
    "\n",
    "lis=[]\n",
    "for i in range(0,len(X)):\n",
    "    temp=X[i]\n",
    "    temp=np.reshape(temp,(1,60))\n",
    "    lis.append(temp)\n",
    "X=np.array(lis)\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_validation, X_test, y_train, y_validation, y_test = prepare_datasets(X,Y,0.25, 0.2)\n",
    "input_shape = (X_train.shape[1], X_train.shape[2], 1)\n",
    "\n",
    "\n",
    "model1 = Classifier()\n",
    "model1.cn(X_train, y_train,X_validation, y_validation,input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1043/1043 [==============================] - 15s 13ms/step - loss: 0.1704 - accuracy: 0.9361 - val_loss: 0.1247 - val_accuracy: 0.9499\n",
      "Epoch 2/100\n",
      "1043/1043 [==============================] - 13s 12ms/step - loss: 0.1162 - accuracy: 0.9590 - val_loss: 0.1033 - val_accuracy: 0.9563\n",
      "Epoch 3/100\n",
      "1043/1043 [==============================] - 13s 12ms/step - loss: 0.0980 - accuracy: 0.9644 - val_loss: 0.0776 - val_accuracy: 0.9711\n",
      "Epoch 4/100\n",
      "1043/1043 [==============================] - 13s 12ms/step - loss: 0.0898 - accuracy: 0.9679 - val_loss: 0.0698 - val_accuracy: 0.9729\n",
      "Epoch 5/100\n",
      "1043/1043 [==============================] - 13s 12ms/step - loss: 0.0831 - accuracy: 0.9702 - val_loss: 0.0939 - val_accuracy: 0.9668\n",
      "Epoch 6/100\n",
      "1043/1043 [==============================] - 13s 12ms/step - loss: 0.0732 - accuracy: 0.9734 - val_loss: 0.0759 - val_accuracy: 0.9770\n",
      "Epoch 7/100\n",
      "1043/1043 [==============================] - 13s 12ms/step - loss: 0.0688 - accuracy: 0.9751 - val_loss: 0.0578 - val_accuracy: 0.9785\n",
      "Epoch 8/100\n",
      "1043/1043 [==============================] - 13s 12ms/step - loss: 0.0670 - accuracy: 0.9759 - val_loss: 0.0581 - val_accuracy: 0.9818\n",
      "Epoch 9/100\n",
      "1043/1043 [==============================] - 15s 14ms/step - loss: 0.0626 - accuracy: 0.9786 - val_loss: 0.0627 - val_accuracy: 0.9767\n",
      "Epoch 10/100\n",
      "1043/1043 [==============================] - 13s 13ms/step - loss: 0.0575 - accuracy: 0.9792 - val_loss: 0.0640 - val_accuracy: 0.9753\n",
      "Epoch 11/100\n",
      "1043/1043 [==============================] - 13s 12ms/step - loss: 0.0544 - accuracy: 0.9811 - val_loss: 0.0896 - val_accuracy: 0.9703\n",
      "Epoch 12/100\n",
      "1043/1043 [==============================] - 13s 12ms/step - loss: 0.0494 - accuracy: 0.9817 - val_loss: 0.0645 - val_accuracy: 0.9743\n",
      "Epoch 13/100\n",
      "1043/1043 [==============================] - 13s 12ms/step - loss: 0.0489 - accuracy: 0.9825 - val_loss: 0.0601 - val_accuracy: 0.9755\n",
      "Epoch 14/100\n",
      "1043/1043 [==============================] - 13s 12ms/step - loss: 0.0450 - accuracy: 0.9843 - val_loss: 0.0640 - val_accuracy: 0.9792\n",
      "Epoch 15/100\n",
      "1043/1043 [==============================] - 13s 12ms/step - loss: 0.0467 - accuracy: 0.9837 - val_loss: 0.0591 - val_accuracy: 0.9809\n",
      "Epoch 16/100\n",
      "1043/1043 [==============================] - 13s 12ms/step - loss: 0.0414 - accuracy: 0.9843 - val_loss: 0.0588 - val_accuracy: 0.9771\n",
      "Epoch 17/100\n",
      "1043/1043 [==============================] - 13s 12ms/step - loss: 0.0449 - accuracy: 0.9842 - val_loss: 0.0969 - val_accuracy: 0.9700\n",
      "Epoch 18/100\n",
      "1043/1043 [==============================] - 14s 13ms/step - loss: 0.0401 - accuracy: 0.9847 - val_loss: 0.0724 - val_accuracy: 0.9769\n",
      "Epoch 19/100\n",
      "1043/1043 [==============================] - 10814s 10s/step - loss: 0.0356 - accuracy: 0.9866 - val_loss: 0.0609 - val_accuracy: 0.9777\n",
      "Epoch 20/100\n",
      "1043/1043 [==============================] - 25311s 24s/step - loss: 0.0367 - accuracy: 0.9867 - val_loss: 0.0529 - val_accuracy: 0.9814\n",
      "Epoch 21/100\n",
      "1043/1043 [==============================] - 17s 16ms/step - loss: 0.0354 - accuracy: 0.9873 - val_loss: 0.0554 - val_accuracy: 0.9824\n",
      "Epoch 22/100\n",
      "1043/1043 [==============================] - 16s 16ms/step - loss: 0.0318 - accuracy: 0.9886 - val_loss: 0.0502 - val_accuracy: 0.9822\n",
      "Epoch 23/100\n",
      "1043/1043 [==============================] - 16s 16ms/step - loss: 0.0323 - accuracy: 0.9883 - val_loss: 0.0555 - val_accuracy: 0.9818\n",
      "Epoch 24/100\n",
      "1043/1043 [==============================] - 18s 17ms/step - loss: 0.0339 - accuracy: 0.9887 - val_loss: 0.0631 - val_accuracy: 0.9801\n",
      "Epoch 25/100\n",
      "1043/1043 [==============================] - 17s 17ms/step - loss: 0.0333 - accuracy: 0.9882 - val_loss: 0.0694 - val_accuracy: 0.9816\n",
      "Epoch 26/100\n",
      "1043/1043 [==============================] - 16s 16ms/step - loss: 0.0274 - accuracy: 0.9899 - val_loss: 0.0903 - val_accuracy: 0.9747\n",
      "Epoch 27/100\n",
      "1043/1043 [==============================] - 16s 15ms/step - loss: 0.0288 - accuracy: 0.9898 - val_loss: 0.0605 - val_accuracy: 0.9824\n",
      "Epoch 28/100\n",
      "1043/1043 [==============================] - 18s 17ms/step - loss: 0.0360 - accuracy: 0.9877 - val_loss: 0.0543 - val_accuracy: 0.9831\n",
      "Epoch 29/100\n",
      "1043/1043 [==============================] - 17s 17ms/step - loss: 0.0227 - accuracy: 0.9922 - val_loss: 0.0811 - val_accuracy: 0.9834\n",
      "Epoch 30/100\n",
      "1043/1043 [==============================] - 19s 18ms/step - loss: 0.0253 - accuracy: 0.9913 - val_loss: 0.0568 - val_accuracy: 0.9818\n",
      "Epoch 31/100\n",
      "1043/1043 [==============================] - 16s 15ms/step - loss: 0.0280 - accuracy: 0.9897 - val_loss: 0.0521 - val_accuracy: 0.9816\n",
      "Epoch 32/100\n",
      "1043/1043 [==============================] - 15s 15ms/step - loss: 0.0269 - accuracy: 0.9908 - val_loss: 0.0804 - val_accuracy: 0.9831\n",
      "Epoch 33/100\n",
      "1043/1043 [==============================] - 18s 17ms/step - loss: 0.0245 - accuracy: 0.9924 - val_loss: 0.0570 - val_accuracy: 0.9818\n",
      "Epoch 34/100\n",
      "1043/1043 [==============================] - 17s 17ms/step - loss: 0.0254 - accuracy: 0.9907 - val_loss: 0.0703 - val_accuracy: 0.9806\n",
      "Epoch 35/100\n",
      "1043/1043 [==============================] - 16s 15ms/step - loss: 0.0229 - accuracy: 0.9922 - val_loss: 0.0495 - val_accuracy: 0.9834\n",
      "Epoch 36/100\n",
      "1043/1043 [==============================] - 17s 16ms/step - loss: 0.0222 - accuracy: 0.9923 - val_loss: 0.0711 - val_accuracy: 0.9852\n",
      "Epoch 37/100\n",
      "1043/1043 [==============================] - 18s 17ms/step - loss: 0.0268 - accuracy: 0.9919 - val_loss: 0.0546 - val_accuracy: 0.9798\n",
      "Epoch 38/100\n",
      "1043/1043 [==============================] - 17s 16ms/step - loss: 0.0234 - accuracy: 0.9926 - val_loss: 0.0612 - val_accuracy: 0.9839\n",
      "Epoch 39/100\n",
      "1043/1043 [==============================] - 16s 15ms/step - loss: 0.0210 - accuracy: 0.9926 - val_loss: 0.0617 - val_accuracy: 0.9818\n",
      "Epoch 40/100\n",
      "1043/1043 [==============================] - 15s 14ms/step - loss: 0.0220 - accuracy: 0.9930 - val_loss: 0.0643 - val_accuracy: 0.9839\n",
      "Epoch 41/100\n",
      "1043/1043 [==============================] - 13s 13ms/step - loss: 0.0217 - accuracy: 0.9927 - val_loss: 0.0803 - val_accuracy: 0.9796\n",
      "Epoch 42/100\n",
      "1043/1043 [==============================] - 15s 14ms/step - loss: 0.0215 - accuracy: 0.9933 - val_loss: 0.0548 - val_accuracy: 0.9782\n",
      "Epoch 43/100\n",
      "1043/1043 [==============================] - 16s 15ms/step - loss: 0.0208 - accuracy: 0.9934 - val_loss: 0.0546 - val_accuracy: 0.9827\n",
      "Epoch 44/100\n",
      "1043/1043 [==============================] - 14s 13ms/step - loss: 0.0250 - accuracy: 0.9923 - val_loss: 0.0675 - val_accuracy: 0.9819\n",
      "Epoch 45/100\n",
      "1043/1043 [==============================] - 14s 13ms/step - loss: 0.0189 - accuracy: 0.9936 - val_loss: 0.0590 - val_accuracy: 0.9828\n",
      "Epoch 46/100\n",
      "1043/1043 [==============================] - 14s 13ms/step - loss: 0.0200 - accuracy: 0.9932 - val_loss: 0.0599 - val_accuracy: 0.9830\n",
      "Epoch 47/100\n",
      "1043/1043 [==============================] - 15s 14ms/step - loss: 0.0205 - accuracy: 0.9941 - val_loss: 0.0729 - val_accuracy: 0.9819\n",
      "Epoch 48/100\n",
      "1043/1043 [==============================] - 14s 14ms/step - loss: 0.0233 - accuracy: 0.9925 - val_loss: 0.0563 - val_accuracy: 0.9844\n",
      "Epoch 49/100\n",
      "1043/1043 [==============================] - 14s 14ms/step - loss: 0.0178 - accuracy: 0.9945 - val_loss: 0.0691 - val_accuracy: 0.9849\n",
      "Epoch 50/100\n",
      "1043/1043 [==============================] - 15s 14ms/step - loss: 0.0188 - accuracy: 0.9939 - val_loss: 0.0604 - val_accuracy: 0.9830\n",
      "Epoch 51/100\n",
      "1043/1043 [==============================] - 14s 14ms/step - loss: 0.0190 - accuracy: 0.9942 - val_loss: 0.0702 - val_accuracy: 0.9830\n",
      "Epoch 52/100\n",
      "1043/1043 [==============================] - 14s 14ms/step - loss: 0.0186 - accuracy: 0.9938 - val_loss: 0.0792 - val_accuracy: 0.9824\n",
      "Epoch 53/100\n",
      "1043/1043 [==============================] - 14s 14ms/step - loss: 0.0277 - accuracy: 0.9906 - val_loss: 0.0579 - val_accuracy: 0.9849\n",
      "Epoch 54/100\n",
      "1043/1043 [==============================] - 15s 14ms/step - loss: 0.0138 - accuracy: 0.9952 - val_loss: 0.0790 - val_accuracy: 0.9849\n",
      "Epoch 55/100\n",
      "1043/1043 [==============================] - 15s 14ms/step - loss: 0.0149 - accuracy: 0.9945 - val_loss: 0.0937 - val_accuracy: 0.9838\n",
      "Epoch 56/100\n",
      "1043/1043 [==============================] - 17s 16ms/step - loss: 0.0213 - accuracy: 0.9939 - val_loss: 0.0620 - val_accuracy: 0.9854\n",
      "Epoch 57/100\n",
      "1043/1043 [==============================] - 15s 15ms/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 0.0887 - val_accuracy: 0.9836\n",
      "Epoch 58/100\n",
      "1043/1043 [==============================] - 16s 15ms/step - loss: 0.0234 - accuracy: 0.9927 - val_loss: 0.0599 - val_accuracy: 0.9844\n",
      "Epoch 59/100\n",
      "1043/1043 [==============================] - 17s 17ms/step - loss: 0.0137 - accuracy: 0.9952 - val_loss: 0.1003 - val_accuracy: 0.9830\n",
      "Epoch 60/100\n",
      "1043/1043 [==============================] - 17s 17ms/step - loss: 0.0163 - accuracy: 0.9951 - val_loss: 0.0617 - val_accuracy: 0.9840\n",
      "Epoch 61/100\n",
      "1043/1043 [==============================] - 17s 16ms/step - loss: 0.0175 - accuracy: 0.9948 - val_loss: 0.0675 - val_accuracy: 0.9849\n",
      "Epoch 62/100\n",
      "1043/1043 [==============================] - 16s 15ms/step - loss: 0.0164 - accuracy: 0.9949 - val_loss: 0.1139 - val_accuracy: 0.9830\n",
      "Epoch 63/100\n",
      "1043/1043 [==============================] - 16s 16ms/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 0.0660 - val_accuracy: 0.9844\n",
      "Epoch 64/100\n",
      "1043/1043 [==============================] - 15s 14ms/step - loss: 0.0195 - accuracy: 0.9940 - val_loss: 0.0712 - val_accuracy: 0.9828\n",
      "Epoch 65/100\n",
      "1043/1043 [==============================] - 15s 14ms/step - loss: 0.0161 - accuracy: 0.9952 - val_loss: 0.1075 - val_accuracy: 0.9822\n",
      "Epoch 66/100\n",
      "1043/1043 [==============================] - 17s 17ms/step - loss: 0.0175 - accuracy: 0.9948 - val_loss: 0.0707 - val_accuracy: 0.9848\n",
      "Epoch 67/100\n",
      "1043/1043 [==============================] - 17s 16ms/step - loss: 0.0139 - accuracy: 0.9951 - val_loss: 0.0848 - val_accuracy: 0.9842\n",
      "Epoch 68/100\n",
      "1043/1043 [==============================] - 16s 15ms/step - loss: 0.0199 - accuracy: 0.9942 - val_loss: 0.0714 - val_accuracy: 0.9795\n",
      "Epoch 69/100\n",
      "1043/1043 [==============================] - 16s 15ms/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 0.0911 - val_accuracy: 0.9852\n",
      "Epoch 70/100\n",
      "1043/1043 [==============================] - 15s 15ms/step - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.1308 - val_accuracy: 0.9825\n",
      "Epoch 71/100\n",
      "1043/1043 [==============================] - 16s 15ms/step - loss: 0.0139 - accuracy: 0.9959 - val_loss: 0.0674 - val_accuracy: 0.9858\n",
      "Epoch 72/100\n",
      "1043/1043 [==============================] - 15s 14ms/step - loss: 0.0171 - accuracy: 0.9947 - val_loss: 0.0787 - val_accuracy: 0.9820\n",
      "Epoch 73/100\n",
      "1043/1043 [==============================] - 21s 20ms/step - loss: 0.0145 - accuracy: 0.9952 - val_loss: 0.0610 - val_accuracy: 0.9844\n",
      "Epoch 74/100\n",
      "1043/1043 [==============================] - 17s 17ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.1384 - val_accuracy: 0.9771\n",
      "Epoch 75/100\n",
      "1043/1043 [==============================] - 21s 20ms/step - loss: 0.0166 - accuracy: 0.9954 - val_loss: 0.0842 - val_accuracy: 0.9820\n",
      "Epoch 76/100\n",
      "1043/1043 [==============================] - 18s 17ms/step - loss: 0.0166 - accuracy: 0.9950 - val_loss: 0.0846 - val_accuracy: 0.9839\n",
      "Epoch 77/100\n",
      "1043/1043 [==============================] - 16s 16ms/step - loss: 0.0178 - accuracy: 0.9943 - val_loss: 0.0872 - val_accuracy: 0.9780\n",
      "Epoch 78/100\n",
      "1043/1043 [==============================] - 17s 16ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.0781 - val_accuracy: 0.9861\n",
      "Epoch 79/100\n",
      "1043/1043 [==============================] - 21s 20ms/step - loss: 0.0164 - accuracy: 0.9950 - val_loss: 0.0570 - val_accuracy: 0.9844\n",
      "Epoch 80/100\n",
      "1043/1043 [==============================] - 18s 17ms/step - loss: 0.0143 - accuracy: 0.9955 - val_loss: 0.0660 - val_accuracy: 0.9849\n",
      "Epoch 81/100\n",
      "1043/1043 [==============================] - 17s 17ms/step - loss: 0.0157 - accuracy: 0.9955 - val_loss: 0.0776 - val_accuracy: 0.9857\n",
      "Epoch 82/100\n",
      "1043/1043 [==============================] - 17s 16ms/step - loss: 0.0157 - accuracy: 0.9952 - val_loss: 0.0782 - val_accuracy: 0.9843\n",
      "Epoch 83/100\n",
      "1043/1043 [==============================] - 22s 21ms/step - loss: 0.0135 - accuracy: 0.9962 - val_loss: 0.0767 - val_accuracy: 0.9831\n",
      "Epoch 84/100\n",
      "1043/1043 [==============================] - 18s 17ms/step - loss: 0.0172 - accuracy: 0.9950 - val_loss: 0.0727 - val_accuracy: 0.9815\n",
      "Epoch 85/100\n",
      "1043/1043 [==============================] - 18s 17ms/step - loss: 0.0177 - accuracy: 0.9947 - val_loss: 0.1916 - val_accuracy: 0.9735\n",
      "Epoch 86/100\n",
      "1043/1043 [==============================] - 21s 20ms/step - loss: 0.0181 - accuracy: 0.9951 - val_loss: 0.0910 - val_accuracy: 0.9831\n",
      "Epoch 87/100\n",
      "1043/1043 [==============================] - 19s 19ms/step - loss: 0.0146 - accuracy: 0.9953 - val_loss: 0.0919 - val_accuracy: 0.9814\n",
      "Epoch 88/100\n",
      "1043/1043 [==============================] - 17s 16ms/step - loss: 0.0143 - accuracy: 0.9955 - val_loss: 0.0749 - val_accuracy: 0.9827\n",
      "Epoch 89/100\n",
      "1043/1043 [==============================] - 21s 20ms/step - loss: 0.0153 - accuracy: 0.9954 - val_loss: 0.0740 - val_accuracy: 0.9858\n",
      "Epoch 90/100\n",
      "1043/1043 [==============================] - 16s 16ms/step - loss: 0.0172 - accuracy: 0.9955 - val_loss: 0.0803 - val_accuracy: 0.9819\n",
      "Epoch 91/100\n",
      "1043/1043 [==============================] - 20s 20ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 0.0783 - val_accuracy: 0.9833\n",
      "Epoch 92/100\n",
      "1043/1043 [==============================] - 22s 22ms/step - loss: 0.0142 - accuracy: 0.9961 - val_loss: 0.0901 - val_accuracy: 0.9822\n",
      "Epoch 93/100\n",
      "1043/1043 [==============================] - 19s 18ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.0864 - val_accuracy: 0.9837\n",
      "Epoch 94/100\n",
      "1043/1043 [==============================] - 19s 19ms/step - loss: 0.0157 - accuracy: 0.9957 - val_loss: 0.0557 - val_accuracy: 0.9855\n",
      "Epoch 95/100\n",
      "1043/1043 [==============================] - 20s 19ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 0.0985 - val_accuracy: 0.9831\n",
      "Epoch 96/100\n",
      "1043/1043 [==============================] - 20s 19ms/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 0.0716 - val_accuracy: 0.9857\n",
      "Epoch 97/100\n",
      "1043/1043 [==============================] - 20s 19ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 0.0886 - val_accuracy: 0.9843\n",
      "Epoch 98/100\n",
      "1043/1043 [==============================] - 19s 18ms/step - loss: 0.0150 - accuracy: 0.9959 - val_loss: 0.0693 - val_accuracy: 0.9848\n",
      "Epoch 99/100\n",
      "1043/1043 [==============================] - 20s 20ms/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 0.1475 - val_accuracy: 0.9816\n",
      "Epoch 100/100\n",
      "1043/1043 [==============================] - 19s 19ms/step - loss: 0.0151 - accuracy: 0.9960 - val_loss: 0.0666 - val_accuracy: 0.9842\n"
     ]
    }
   ],
   "source": [
    "#speech vs music training\n",
    "\n",
    "\n",
    "x_speech = readDir('C:/Users/HP/Documents/test/speech', 16000)\n",
    "x_music = readDir('C:/Users/HP/Documents/test/music', 16000) \n",
    "X = np.concatenate((x_speech, x_music))\n",
    "y_speech = np.array([[1,0]]*len(x_speech))\n",
    "y_music= np.array([[0,1]]*len(x_music))\n",
    "Y = np.concatenate((y_speech, y_music))\n",
    "\n",
    "\n",
    "\n",
    "lis=[]\n",
    "for i in range(0,len(X)):\n",
    "    temp=X[i]\n",
    "    temp=np.reshape(temp,(1,60))\n",
    "    lis.append(temp)\n",
    "X=np.array(lis)\n",
    "\n",
    "\n",
    "X_train, X_validation, X_test, y_train, y_validation, y_test = prepare_datasets(X,Y,0.25, 0.2)\n",
    "input_shape = (X_train.shape[1], X_train.shape[2], 1)\n",
    "\n",
    "\n",
    "model2 = Classifier()\n",
    "model2.cn(X_train, y_train,X_validation, y_validation,input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/HP/Documents/test/model1_cnn\\assets\n",
      "INFO:tensorflow:Assets written to: C:/Users/HP/Documents/test/model2_cnn\\assets\n"
     ]
    }
   ],
   "source": [
    "model1.model.save('C:/Users/HP/Documents/test/model1_cnn')\n",
    "model2.model.save('C:/Users/HP/Documents/test/model2_cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio vs no audio prediction\n",
    "\n",
    "data = readDir('C:/Users/HP/Documents/test/unknown/', 16000) # This will work for single file in folder. For multiple files, WE can run this in a loop for every unknown audio file in folder\n",
    "lis=[]\n",
    "for i in range(0,len(data)):\n",
    "    temp=data[i]\n",
    "    temp=np.reshape(temp,(1,60))\n",
    "    lis.append(temp)\n",
    "data=np.array(lis)\n",
    "\n",
    "data = data[..., np.newaxis]\n",
    "\n",
    "p = model1.model.predict(data)\n",
    "\n",
    "for i in range(0, len(p)):\n",
    "    if(p[i][1]>0.5):\n",
    "        p[i][0]=0\n",
    "        p[i][1]=1\n",
    "    else:\n",
    "        p[i][0]=1\n",
    "        p[i][1]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.864, 2.784],\n",
       "       [3.776, 6.208],\n",
       "       [6.944, 9.408],\n",
       "       [0.   , 0.   ],\n",
       "       [0.   , 0.   ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Time label prediction\n",
    "\n",
    "k=0\n",
    "j=0\n",
    "sil=np.array([[0.0,0.0],[0.0,0.0],[0.0,0.0],[0.0,0.0],[0.0,0.0]])\n",
    "sp=np.array([[0.0,0.0],[0.0,0.0],[0.0,0.0],[0.0,0.0],[0.0,0.0]])\n",
    "\n",
    "def check(x):\n",
    "    sum=0\n",
    "    for i in range(0,len(x)):\n",
    "        sum=sum+x[i][0]\n",
    "    if(sum>=10):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "    \n",
    "prev=1\n",
    "\n",
    "for i in range(0,len(p)-16):\n",
    "    x=p[i:i+16]\n",
    "    a=check(x)\n",
    "    #print(a)\n",
    "    if(a==1):\n",
    "        if(prev==1):\n",
    "            sil[j][1]=librosa.frames_to_time(i+22, sr=16000, hop_length=512, n_fft=1024)\n",
    "        else:\n",
    "            temp=i\n",
    "            while(p[i][0]!=1):\n",
    "                i+=1\n",
    "            sp[k][1]=librosa.frames_to_time(i, sr=16000, hop_length=512, n_fft=1024)\n",
    "            sil[j][0]=librosa.frames_to_time(i, sr=16000, hop_length=512, n_fft=1024)\n",
    "            sil[j][1]=librosa.frames_to_time(temp+22, sr=16000, hop_length=512, n_fft=1024)\n",
    "            k+=1\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        if(prev==1):\n",
    "            temp=i\n",
    "            while(p[i][1]!=1):\n",
    "                i+=1\n",
    "            sil[j][1]=librosa.frames_to_time(i, sr=16000, hop_length=512, n_fft=1024)\n",
    "            sp[k][0]=librosa.frames_to_time(i, sr=16000, hop_length=512, n_fft=1024)\n",
    "            sp[k][1]=librosa.frames_to_time(temp+22, sr=16000, hop_length=512, n_fft=1024)\n",
    "            j+=1\n",
    "        \n",
    "        else:\n",
    "            sp[k][1]=librosa.frames_to_time(i+22, sr=16000, hop_length=512, n_fft=1024)\n",
    "    prev=a      \n",
    "\n",
    "    \n",
    "sp  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 86\n",
      "117 193\n",
      "216 293\n"
     ]
    }
   ],
   "source": [
    "#Extracting audio portions\n",
    "\n",
    "lis=[]\n",
    "for i in range(len(sp)):\n",
    "    if(sp[i][0]==0 and sp[i][1]==0):\n",
    "        continue\n",
    "    else:\n",
    "        lis.append(np.array([sp[i][0],sp[i][1]]))\n",
    "sp=np.array(lis)\n",
    "\n",
    "\n",
    "lis=[]\n",
    "for i in range(0,len(sp)):\n",
    "    start= librosa.time_to_frames(sp[i][0], sr=16000, hop_length=512, n_fft=1024)\n",
    "    end = librosa.time_to_frames(sp[i][1], sr=16000, hop_length=512, n_fft=1024)\n",
    "    print(start,end)\n",
    "    lis.append(np.array(data[start:end]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.864 2.784 speech\n",
      "3.776 6.208 speech\n",
      "6.944 9.408 speech\n"
     ]
    }
   ],
   "source": [
    "#Labels of extracted audio portions\n",
    "frame_pred= predict_framewise(model2,lis)\n",
    "\n",
    "agg=predict_aggregate(frame_pred)  \n",
    "\n",
    "for i in range(len(sp)):\n",
    "    print(sp[i][0],sp[i][1], 'speech' if (agg[i][0]==1) else  'music')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
